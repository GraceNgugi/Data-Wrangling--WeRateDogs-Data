{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA WRANGLING PROCESS IN THE WE RATE DOG DATASETS\n",
    "Data wrangling is the process of gathering data, assessing its quality and structure, and cleaning it before you do things like analysis, visualization.\n",
    "### DATA SETS USED\n",
    "1. Twitter Archive Data\n",
    "2. Image prediction Data\n",
    "3. Tweet API data\n",
    "\n",
    "### GATHERING\n",
    "1. Uploaded the twitter archive data to my notebook and read it using pandas as csv.\n",
    "2. Used the requests function to gather this data and created a dataframe to store this data.\n",
    "3. Used the tweet API data provided in the udacity class to get the retweet count and favorite count data that was needed for this analysis. \n",
    "\n",
    "### ACCESSING DATA\n",
    "In access data, I used the visual and programmatic assessment\n",
    "1. VISUAL ASSESSEMNT involves looking at your dataset in its entirety in whatever program you like.You can use google sheet, excel or scroll through your data to identify quality and tidiness issues. \n",
    "2. PROGRAMMATIC ASSESSMENT uses functions and methods to reveal something about your data's quality and tidiness.\n",
    "\n",
    "***findings***\n",
    "1. Quality issues\n",
    "\n",
    "Low quality data is commonly referred to as dirty data. Dirty data has issues with its content. \n",
    "\n",
    "***8 Quality issues identified in this datasets***\n",
    "1. There are 78 replies in tweets (in_reply_to_status_id, in_reply_to_user_id) missing 2278. \n",
    "2. 181 retweets in (retweeted_status_id , retweeted_status_user_id   ,retweeted_status_timestamp) missing 2175. \n",
    "3. There are 2297 expanded_urls with 59 tweets missing data. \n",
    "4. The name column had invalid names such as \"a\",\"an\", \"None\".\n",
    "5. Timestamp data type representend as object which is type 'str'.\n",
    "6. The rating denominator should be 10 for all fields. \n",
    "7. The tweet id data type should be string not int. \n",
    "8. Change the name of id column in the tweet data to tweet_id to match that of twitter archive data and image predictions data. \n",
    "\n",
    "2. Tidiness issues\n",
    "Untidy data is commonly referred to as \"messy\" data. Messy data has issues with its structure.\n",
    "\n",
    "***Tidiness issues obtained from this datasets***\n",
    "1. The dog stages included in separate columns like 'doggo','floofer','pupper','puppo'\n",
    "2. There are three datasets which should be merged to one dataset. \n",
    "\n",
    "### CLEANING\n",
    "After accessing the data, the next step is to clean this data. I used the following steps to clean the data. \n",
    "\n",
    "Define - define how you will clean the issue in words\n",
    "\n",
    "Code - convert your definitions into executable code\n",
    "\n",
    "Test - test your data to ensure your code was implemented correctly\n",
    "\n",
    "Some of the defined issues in this dataset included:\n",
    "\n",
    "1. The first step was to make ***copies*** of the original datasets. \n",
    "2. Converting timestamp and tweet_id datatypes to datetime and string respectively.\n",
    "3. Merge the three datasets to one dataset using the merge function.\n",
    "4. Rename the id column in tweet data to tweet_id to match with the image prediction and twitter archive data.\n",
    "5. Combining the dog stage columns to one column called the dog stage. \n",
    "6. Checking for missing values and dropping all columns with missing values in this datasets that were not necessary for the analysis. \n",
    "7. Replace the 'None' with 'NAN'\n",
    "\n",
    "Converted the merged dataset to csv. \n",
    "\n",
    "### ANALYSING\n",
    "The final stage was anlyzing the data to draw meaningful insights. \n",
    "1. Checked the most popular dog stage and plotted their percentages.\n",
    "2. Checked the correlation between the retweet count and favorite count.\n",
    "3. Checked the distribution of ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
